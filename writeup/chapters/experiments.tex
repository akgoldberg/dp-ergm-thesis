  It is typical in the literature on inference for ERGMs to evaluate performance empirically through experiments  (\cite{HH06}, \cite{LM14}, \cite{HG10}). This is because there are no general theoretical results on the utility of non-private inference. In this chapter, we conduct a series of experiments, both on synthetic graphs drawn from a variety of ERGMs and on a high school friend network dataset collected by sociologists. For the edge-level privacy model, we compare the accuracy in releasing differentially private sufficient statistics using our proposed method of calibrating noise to restricted sensitivity against the private local sensitivity. Next, we compare the quality of parameter estimation using our proposed inference method with restricted sensitivity, private bounding of local sensitivity and randomized response used to perturb the network data. Finally, we evaluate the noise addition of our method under node-level privacy. We give a brief summary of our main findings in this chapter in Section \ref{sec:summary_findings}.
  
  %We find that in the edge-level model our method allows for much more accurate parameter estimation than existing methods, which do not enable useful inference for small privacy budgets. Further, we demonstrate that it is possible to perturb the sufficient statistics of large networks relatively little. Extrapolating from inference results in the edge-level privacy model, the low error in computing sufficient statistics for large sparse networks under node-level privacy constraints suggests that inference using our method is viable for this stronger privacy model. 
 
 \section{Experimental Setup}\label{sec:setup}
 
 \subsubsection*{Data}
 	We test our proposed methods on networks drawn from three different ERGM specifications using the alternating structural sufficient statistics introduced in \Cref{sec:alt_stats}, so the probability distribution has the form:
 	$$\Pr(x | \theta) \propto \exp\left\{\theta_1 E(x) + \theta_2 u_\lambda^{(s)}(x) + \theta_3 u_\gamma^{(t)}(x)  + \theta_4 u_\gamma^{(p)}(x)\right\} $$
 	 with the following parameters for each model:
 	\begin{table}[!ht]
 		\centering
 		\begin{tabular}{|c|c|c|c|c|}
 			\hhline{|=====|}
 			Model & $\theta_1$ (Edges) & $\theta_2$ ($k$-Stars) & $\theta_3$ ($k$-Triangles) & $\theta_4$ ($k$-Two-Paths) \\ \hline
			1 & -4.6 & 0.0 & 1.0 & 0.0  \\
			2 & -4.6 & 0.0 & 2.0 & -0.1 \\
			3 & -4.6 & 2.0 & 2.0 & -0.5 \\
			\hhline{|=====|}
 		\end{tabular}
 	\caption{Parameters of synthetic networks}
 	\label{table:ergm_params}
 	\end{table}
 
 	 We fix the edge parameter at $-4.6$, because in the absence of any other sufficient statistics this corresponds to a $G(n,p)$ model with $p = 1\%$, leading to sparse networks. Then, the other parameters are chosen based on typical values from analyses of real network data, with Model $1$ constituting a simple model introducing only the alternating $k$-triangle parameter in addition to edges and Model $3$ representing the most complex model, including all four structural parameters. In Model $2$, we incorporate a two-path parameter in addition to the triangle parameter, because the small negative parameter encourages sparsity while still leading to a large number of triangles in the network. In all three models we use a positive parameter for triangles, because triangulation is one of the most distinctive structures of networks captured by ERGMs that other stochastic models of networks frequently have difficulty capturing. Additionally, triangle count is one of the most difficult statistics to compute privately as it has high sensitivity relative to the scale of the statistic. 
 	 
 	We simulate networks using the sampling method detailed in \Cref{sec:sim_ergm} for graphs on $n$ nodes with $n$ ranging from $100$ to $1000$ in order to study networks with a range of sizes. Current standard inference methods for ERGMs are generally computationally feasible only for networks of around $1000$ nodes at most, hence our choice of this upper limit on the size of the networks.\footnote{Indeed, current work (\cite{LM14}, \cite{KKS17}) only evaluates differentially private inference on networks of under $150$ nodes, which are too small to perform accurate private inference on under strong privacy constraints.} For each $n$ and each model we draw $50$ networks. Looking at the structure of the simulated networks in Figure \ref{fig:priv_structure} indicates that the $3$ models put most of their probability mass on distinctive networks. On average, networks drawn from Model $1$  have edge density (proportion of possible edges present) of $6\%$, networks from Model $2$ have average density of $1\%$, and networks from Model $3$ average $0.5\%$.  Further, the max degree and triangle counts of the networks vary highly between the three models.
 	
 	\begin{figure}[!h]
 		\centering
 		\includegraphics[width=0.95\textwidth]{samples_summary.png}
 		\caption{Degree of simulated networks (with shading indicating max and min over the $50$ samples and dashed line showing median degree) along with the mean triangle count for simulated networks.}
 		\label{fig:priv_structure}
 	\end{figure}
 
 	 Networks drawn from Model $1$ have the highest degree and triangle count, while networks simulated from Model $2$ have approximately three times as many triangles as networks from Model $3$. Additionally, all three models capture more complex structure in networks than the basic $G(n,p)$ model with $p = 1\%$, for which simulated networks tend to have only one tenth the number of triangles as Model $3$ despite having higher edge density.  
 	
 	 In addition to the simulated networks, we test our methods on a dataset known as the ``Faux Mesa High School Network'', which is a publicly available social network released by sociologists who studied high schools in the Southwestern United States. These researchers surveyed the entire student body of a high school and formulated a social network with $205$ nodes corresponding to students (labeled with attributes like Race and Sex) and $203$ undirected edges representing reported mutual friendships between students \cite{ergm}. The publicly available network on which we test inference was generated by researchers by fitting an ERGM to the dataset and then releasing a network sampled from this distribution. This suggests that privacy was a concern for the underlying network data. Therefore, the synthetic network maintains the interesting structural properties of the underlying dataset. Performing inference over this dataset allows us to evaluate whether researchers would reach similar conclusions using our proposed differentially private inference methods as using standard non-private inference. 
  
\subsubsection*{Implementation}

Below, we give a number of important implementation details that apply to all conducted tests:
\begin{itemize}
	\item Code is written in the \texttt{R} programming language, with the procedure for sampling networks used for inference built on top of the packages \texttt{ergm} \cite{ergm} and \texttt{Bergm} \cite{Bergm}, which support non-private inference over ERGMs.
	\item In order to explore a broad parameter space and compare a variety of approaches, the experiments ran in parallel on Harvard's Odyssey computing cluster. To speed up individual experiments (which was particularly important during initial debugging), the  inference step exploited thread level parallelism  on 32-core machines.
	\item Unless otherwise specified, we give overall privacy budget (in terms of $\eps$ and $\delta$), which is evenly split between sufficient statistics needed for inference, employing the composition property of differential privacy. Throughout, when we guarantee the relaxed notion of $(\eps, \delta)$-DP we set the privacy budget of $\delta$ to $10^{-6}$ in order to give a meaningful privacy guarantee akin to that of pure $\eps$-differential privacy.
	\item For all parameters, we specify an ``uninformative'' prior of $\N(0, 50)$ in inference. Since parameter estimates are generally small compared to the variance of the prior, this prior has little effect on the posterior parameter estimates.  It may be possible to improve performance by incorporating simple prior information, like the expected signs of parameters, about which researchers often have beliefs, which may be an interesting notion to investigate in future work.
	\item To obtain point estimates of fitted parameters, we take the mean of the posterior distribution over parameters, which is standard practice for Bayesian inference on ERGMs \cite{CF11}.
\end{itemize}
 
 \section{Edge-Adjacency Model}
 
Under edge-level privacy constraints, we compare our proposed method against two alternative methods, the private bound on local sensitivity approach suggested by Lu and Miklau \cite{LM14} and the randomized response method of Karwa et al. \cite{KKS17}, both detailed in Section \ref{sec:rel_work}. Since the private local sensitivity method also adds noise to sufficient statistics and then performs inference just as our restricted sensitivity-based method does, we first compare the noise addition step between these methods. We find that restricted sensitivity allows for much lower noise addition, measured in terms of root-mean-square error, especially at small values of $\eps$. 

Then, we evaluate how difference in perturbation of the network data impacts quality of inference. We compare the performance of differentially private inference between the three methods by looking at how close parameter estimates are to the ``ground-truth'' parameters. For the three synthetic networks, we take ground-truth to be the true parameters of the ERGMs from which we drew synthetic data (specified in Table \ref{table:ergm_params}) while for the Mesa high school data we learn parameters non-privately and take these to be a best guess of true parameters.   
 
 \subsection{Noise Addition Comparison}
 
 \subsubsection{Setup}
 For noise addition comparisons, we test the error introduced by perturbing sufficient statistics for the three synthetic network models and all values of $n$. We compare noise addition under restricted sensitivity with various max degree cutoffs and private local sensitivity. For each of the $50$ networks of size $n$ drawn from a model, we draw noise $50$ times for each noise addition method, resulting in $2500$ simulated noise draws for each $n$. We compute the four sufficient statistics (edges, alt-$k$-star, alt-$k$-triangle, and alt-$k$-two-path) with privacy levels per-statistic of $\eps = 0.025, 0.125,$ and $0.25$ (so by the composition property of differential privacy, overall privacy budgets using the $4$ statistics $0.1, 0.5,$ and $1$ respectively) and display results below for the largest per-statistic budget of $\eps = 0.25$. For the private bounding of local sensitivity, which can only guarantee $(\eps, \delta)$-DP, we use an overall budget of $\delta = 10^{-6}$ so that the privacy guarantee is comparable to that of pure $\eps$-differential privacy. 
 
 Further, we test varying degree cutoffs $k$ of the restricted degree hypothesis. Lower (more aggressive) setting of $k$ allows for less Laplace noise to be added since the restricted sensitivity is smaller. However, if $k$ is lower than the true degree of the network, then the projection to the space of networks of degree $k$ requires removing edges from the network, introducing bias into the released sufficient statistics.  Since mean square error is variance plus squared bias, using RMSE captures both the error from projection bias and from Laplace noise addition. Specifically, we test three choices of $k$:
 \vspace{-0.2in}
\begin{enumerate}
	\item Take $k$ equal to the minimum degree over the $50$ networks drawn from a given model, which may allow for low Laplace noise, but at the expense of potentially high bias induced by removing many edges.
	\item Take $k$ to be the median degree over the $50$ networks, allowing relatively low scale of Laplace noise, while also introducing limited bias since the edge-level projection  requires removing edges from nodes that have degree higher than $k$ of which we expect there to be relatively few.
	\item Take $k$ to be a conservative estimate of $1.5$ times the maximum degree of the $50$ networks drawn from a given model, which guarantees that we never under-estimate the degree of a network. 
\end{enumerate}
In the plots that follow, we refer to these settings of $k$ as `min', `median' and `conservative' respectively.

 \subsubsection{Results}
 \begin{figure}[hp]
 	\caption{Comparison of Relative RMSE of edge-DP sufficient statistics released at a privacy level of $\eps = 0.25$-per statistic. Laplace noise is scaled to either a private bound on local sensitivity or to restricted sensitivity with $3$ settings of degree cutoff $k$.}
 	\label{fig:edge_noise}
 	\centering
 	\input{figures/noise_tests_edge.tex}
 \end{figure}
 
As comparison of noise in Figure \ref{fig:edge_noise} demonstrates, for $\eps = 0.25$ per statistic, our proposal of scaling noise to restricted sensitivity introduces much lower error into sufficient statistics than the private bounding of local sensitivity described in Section \ref{sec:rel_work}. The difference in noise addition is larger for the sparser networks drawn from Models $2$ and $3$, than for networks drawn from Model $1$ because the degree of these networks is lower, giving a restricted sensitivity bound closer to the local sensitivity of the statistics. Further, the scale of noise added in the private bound on local sensitivity (as discussed in \ref{sec:rel_work}) is $O\left(\frac{LS}{\epsilon} + \frac{\log(1/\delta)}{\epsilon^2}\right)$, whereas restricted sensitivity adds noise scaled to $O\left(\frac{RS}{\epsilon}\right)$. Therefore, as $\epsilon$ gets smaller, the $\frac{1}{\epsilon^2}$ term grows faster than the $\frac{1}{\eps}$ term leading to even higher noise addition for private bounding of local sensitivity. Consistent with this observation, for tests run with smaller $\epsilon$ of $0.025$ and $0.125$-per statistic, we observed that restricted sensitivity outperforms private local sensitivity in the amount of noise added by an even larger margin. This suggests that for smaller overall privacy budgets than $\epsilon=1$ or for cases where we introduce more sufficient statistics (for instance, when we want terms incorporating nodal attributes) so that we must split the privacy budget between additional terms, restricted sensitivity will dominate private local sensitivity by an even larger factor.

Comparing the RMSE of statistics to the true values, we observe that restricted sensitivity may permit inference in settings where the noise added by private local sensitivity would overwhelm the true statistic value. For instance, looking at the lower left subplot in Figure \ref{fig:edge_noise}, for networks with $300$ nodes drawn from Model $3$, the RMSE of the $k$-triangle statistic is over three times the value of the true statistic when noise is scaled to private local sensitivity, while restricted sensitivity adds noise under half the true statistic value. Further, we observe that as networks grow larger the error relative to the size of the network decreases, since the degree of the network remains low, while the magnitude of the sufficient statistics increases, allowing for lower noise addition relative to the magnitude of the statistics.

Comparison of the different thresholds for the degree cutoff $k$ suggests that even a conservative cutoff outperforms private local sensitivity. However, choosing a more aggressive cutoff leads to much lower error, indicating that the lowered variance induced by Laplace noise addition has a larger impact on error than the bias introduced by removing edges from high-degree nodes in networks of degree larger than $k$. In fact, for the alternating $k$-triangle and the alternating $k$-two-path statistics, using the min $k$ cutoff, such that the degree of all simulated networks is beneath the cutoff, slightly outperforms restricted median. However, this aggressive setting of the cutoff introduced more bias into the edges and alt $k$-star terms. While the median cutoff leads to the removal of less than $0.05\%$ of edges in the network for all $n$, the min cutoff leads to the removal of around $0.3\%$ of edges. Additional testing with a highly aggressive cutoff of $0.75(\text{min degree})$ led to the removal of $7-8\%$ of edges, making the RMSE of released private statistics higher for this setting than for the conservative cutoff. The ability to use cutoffs slightly below the actual degree of networks, while introducing low bias to computed statistics, most likely arises because ERGMs tend to capture power laws of degree distributions, such that there are relatively few nodes with degree close to the max degree. Therefore, choosing a cutoff below the max degree leads to the removal of only a few edges incident to these few nodes, skewing the structure of the network very little. Our comparison indicates that setting $k$ equal to the median of all max degrees for simulated networks constitutes a good choice of $k$, so we use this setting of $k$ in our inference tests. 

Overall, our tests suggest that for reasonable choices of privacy budget $\epsilon$, restricted sensitivity introduces much lower error to sufficient statistics than privately bounding local sensitivity. Further, aggressively setting the degree cutoff $k$ to be beneath the max degree of actual networks can decrease the overall error in privatizing network statistics. 

 \subsection{Inference Comparison on Synthetic Networks}
 
 Next, we test how the differing approaches to perturbing the network data impact the quality of inference. We find that for small privacy budgets our proposed method outperforms randomized response and for either small privacy budgets or the use of many sufficient statistics our method outperforms private bounding of local sensitivity. 
 
 \subsubsection{Setup}
 
 We test the performance of private inference on networks drawn from of each of the three models with overall privacy budgets of $\epsilon=1$ and $\epsilon=3$. Specifically, for $N=25$ tests of inference, we randomly choose one of the $50$ networks on $300$ nodes drawn from a model and run inference on this network to learn the parameters of the model from which the network was drawn. This implies that Model $1$ has the largest privacy budget per-statistics, since we split the fixed privacy budget over only the $2$ statistics for Model $1$, $3$ statistics for Model $2$, and $4$ statistics for Model $3$. We test inference on networks of $300$ nodes because private inference is expected to have higher utility on larger networks (as the amount of added noise is lower compared to the value of true statistics as shown in Figure \ref{fig:edge_noise}) but running a relatively large number of tests on networks with more than $300$ nodes was computationally infeasible within the scope of this work. For the small privacy budget of $\epsilon=1$, the inference method using randomized response fails to converge (which is unsurprising, because this corresponds to a probability of over $25\%$ of flipping each edge in the network, so the posterior distribution spreads probability mass over a very large range of possible networks.) Therefore, for $\epsilon=1$ we only report results for private local sensitivity and restricted sensitivity, while for $\epsilon = 3$ (corresponding to a flipping probability of $5.6\%$ in randomized response), we report results for all three methods. We display the distribution of parameter estimates using boxplots (which denote min, max, quantiles and median parameter estimates) against the ground truth parameters shown as dashed black lines. Additionally, we display the results of running non-private inference $25$ times, which represents the best possible performance we could expect from differentially private inference. Non-private inference tends to be have low variance in parameter estimates across tests, as we fit networks using the models from which synthetic networks were drawn, thereby controlling for inference error caused by mis-specification of the model.
 
 \subsubsection{Results}
 
  \begin{figure}[!h]
 \caption{Differentially private parameter estimates for $300$-node synthetic networks drawn from \emph{Model $\mathit{1}$}. The dashed black line denotes ground-truth parameter values. We abbreviate randomized response as ``rr''.}
 \centering 
 \includegraphics[width=0.5\linewidth]{figures/inference/legend.png}
 \includegraphics[width=0.6\linewidth]{figures/inference/paramplot1.png}
 \label{fig:edgeinfsynth1}
\end{figure}

  \begin{figure}[!h]
	\caption{Parameter estimates for $300$-node synthetic networks drawn from \emph{Model $\mathit{2}$}.}
	\centering 
	\includegraphics[width=0.5\linewidth]{figures/inference/legend.png}
	\includegraphics[width=0.7\linewidth]{figures/inference/paramplot2.png}
	\label{fig:edgeinfsynth2}
\end{figure}
 
  \begin{figure}[!h]
	\caption{Parameter estimates for $300$-node synthetic networks drawn from \emph{Model $\mathit{3}$}.}
	\centering 
	\includegraphics[width=0.5\linewidth]{figures/inference/legend.png}
	\includegraphics[width=0.75\linewidth]{figures/inference/paramplot3.png}
	\label{fig:edgeinfsynth3}
\end{figure}

Model $1$ uses only two sufficient statistics, allowing for high values of $\epsilon$ per statistic, since the privacy budget is split between few statistics. Additionally, only the $k$-triangle statistic has high sensitivity, as edges have a global sensitivity of $1$ (Table \ref{tab:altsuffstatsrestr}). For the privacy budget of $\eps=1$, restricted sensitivity slightly outperforms private local sensitivity in the accuracy of parameter estimation as shown in Figure \ref{fig:edgeinfsynth1}. This is because restricted sensitivity has added slightly less noise to the alternating $k$-triangle statistic than private local sensitivity: restricted introduces a relative RMSE of $0.3$ to the statistic, while private local introduces a relative RMSE of $0.35$. Our inference tests demonstrate that using noisy sufficient statistics with error at this level still allows for highly accurate parameter estimates. Thus, extrapolating to larger networks where even less noise can be added relative to the magnitude of sufficient statistics, we expect to be able to accurately estimate parameters with smaller privacy budgets. In contrast to adding noise to sufficient statistics, randomized response performs poorly even at the privacy budget of $\eps = 3$, for which each edge is flipped with probability $4.7\%$. This perturbation of edges heavily distorts network structure, leading the network to resemble a denser $G(n,p)$ network, as randomized response underestimates the $k$-triangle parameter and overestimates the edge parameter.

 Model $2$ introduces a third sufficient statistic, requiring the privacy budget to be split between $3$ statistics instead of $2$ as in Model $1$. This leads private local sensitivity to perform poorly at $\eps=1$, as adding noise to the alt-$k$-triangle statistic overwhelms the value of the statistic, which leads parameter estimates to vary wildly as shown in Figure \ref{fig:edgeinfsynth2}. For $\eps=1$, restricted sensitivity gives better estimates of the edge and alt-$k$-two-path parameters than private local does. Using restricted sensitivity, we consistently estimate the alternating $k$-triangle statistic to be much larger than $0$ and the alternating $k$-two-path statistic to be slightly negative, suggesting that researchers could accurately discern the importance of these network structures using differentially private inference. Also, we observe that even non-private inference produces biased parameter estimates compared to ground-truth, which points to underlying stochasticity in parameter estimation inherent in the specification of the synthetic network model. Relative to the error of non-private inference, private inference using restricted sensitivity performs approximately two times worse in estimating parameters at $\eps = 3$. Finally, we observe for Model $2$ as for Model $1$ that randomized response lead to parameter estimates that describe a $G(n,p)$ graph, with two-path and triangle parameters close to $0$, indicating the loss of important substructure in the perturbed network when applying randomized response.
 
 As we see in Figure \ref{fig:edgeinfsynth3}, for Model $3$, which uses all $4$ sufficient statistics, private local sensitivity does not enable useful inference even for $\epsilon=3$, as the average bias of parameter estimates is over $2$ times the value of the parameters. However, restricted sensitivity gives reasonable parameter estimates that would permit a researcher to understand the relative importance of the various alternating sufficient statistics in describing network structure. In contrast, private local sensitivity gives highly biased estimates of the two-path and edges parameters and has much higher variance for alt $k$-star and alt $k$-triangle, confirming that as more parameters are added, so that the privacy budget needs to be split between multiple statistics, restricted sensitivity increasingly outperforms private local sensitivity.

  \subsection{Inference Comparison on Mesa High School Data}
  
  To understand how differential privacy impacts analysis of network data in practice, we provide a case study of differentially private inference on a high school friend network where nodes are labeled by race and sex. In line with demographers analyses of high school friend networks in \cite{GKM09}, we study various processes of social network formation including homophily by race and sex and triangulation. Because the network is relatively small with $203$ nodes, we are not able to provide useful inference while taking labels as private, for this case it may be reasonable to assume that Race and Sex of nodes are public information and treat labels as public. 
  
 \subsubsection{Setup}
 
 We apply the three private inference approaches -- restricted sensitivity, private local sensitivity, and randomized response -- to the Mesa High School Friend Network. We run $25$ tests of inference for each method and $\eps \in \{1,3\}$. For the restricted degree cutoff we take $k=15$, whereas the real network has max degree $13$. We choose degree $15$, as a realistic estimate of the max degree of the network based on similar published datasets collected by sociologists at high schools \cite{ergm}, as students administered surveys tend to not list more than $15$ friends. Based on models used to study high school friendship networks in the published literature on the subject \cite{GKM09} as well as the models used for non-private inference on this particular network \cite{ergm} we fit the a model to the data incorporating `Sex' and `Race' labels on nodes. Race can take on one of five values -- Black, Hispanic, Native American, White, and Other -- while sex is either Male or Female. We use the $k$-triangle statistic as well as measures of overall homophily by race, homophily among men, and homophily among women. We perform non-private inference using $25$ tests and find that it gives consistent parameter estimates across test runs, suggesting that our model is well-specified. Thus, we take mean parameter estimates across all $25$ tests as ground truth parameters. 
 
  \subsubsection{Results}
	
	Compared to both adding noise scaled to private bound local sensitivity and randomized response, our proposed method using restricted sensitivity allows for accurate parameter estimation at lower privacy budgets. As we show in Table \ref{tab:infacc}, restricted sensitivity with $\eps=1$ gives estimates of edges and alternating $k$-triangle that are unbiased overall, although with fairly high error. For $\eps=2$, restricted sensitivity gives consistently accurate parameter estimates for all parameters except Male homophily. However, the non-private estimate for this parameter in Table \ref{tab:infalttyp} is not statistically significant, so it is unsurprising that perturbing the statistics leads to differing estimates of this parameter. In contrast, private local sensitivity even with overall privacy budget of $\eps=3$ is highly unstable returning parameter estimates with wildly varying values as evidenced by the high MSE and MAE of the parameter estimate. This is due to the splitting of the privacy budget between parameters, which leads to high noise addition to the $k$-triangle statistic when calibrating noise to private local sensitivity. Randomized response with $\eps=3$ overwhelms interesting structure of the network, leading all parameter estimates to be close to $0$ except for edges.
  
	\begin{table}[!ht]
	 	\caption{Average differentially private parameter estimates, mean-square error, and bias for $25$ differentially private inference test runs on Mesa High School Friend Network.} 
	 	\label{tab:infacc}
	 	\centering
	 	\input{figures/edge_table_accuracy_RS.tex}
	 	{\vskip 1em}
	 	\input{figures/edge_table_accuracy_alt.tex}
	\end{table}

	As shown in Table \ref{tab:infalttyp}, for private inference with $\eps=1$ there is a large increase in standard errors, demonstrating that inference over the private posterior distribution captures the uncertainty in true sufficient statistics introduced by the privacy mechanism. This increased uncertainty means that parameter estimates are no longer significant for $\eps = 1$. However, for $\eps = 2$, homophily by race, homophily among women, the edges parameter and the $k$-triangles parameter all remain statistically significant and close to the original parameters. This suggests that, in the typical case, a researcher performing differentially private using the restricted sensitivity approach with $\eps=2$ would reach the same conclusions about network structure as under non-private inference -- that the network is sparse, that triangulation, or tendency for friends-of-friends to become friends, constitutes an important process in network formation, and that homophily has a significant impact on formation of friendship between people of the same race and between women, but not for men.  
	
		\begin{table}[!h]
		\caption{Typical parameter estimates and standard errors for differentially private inference on Mesa Data.``Typical'' estimates denote the test run with median overall error in parameter estimates (normalized by magnitude of the parameters.)} 
		\label{tab:infalttyp}
		\centering
		\input{figures/edge_table_typical.tex}
	\end{table}

	Overall, the results from this case study suggest that, in contrast to current methods, using restricted sensitivity to perturb sufficient statistics of a network enables researchers to reach meaningful conclusions about the processes giving rise to network structure for reasonable privacy budgets. For similar, even larger, sparse friend networks -- which are common in the sociology and demography literature --  it should be feasible to perform useful inference with even smaller privacy budgets as the magnitude of sufficient statistics will be larger compared to the max degree of the network. 
 
 \section{Node-Adjacency Model}
 
   Finally, we assess the level of noise addition in releasing node-differentially private sufficient statistics of ERGMs. We test the error introduced by calibrating noise to restricted sensitivity for a range of different degree cutoffs and for the two different projections detailed in \Cref{appendix_projections}. Comparing the level of noise addition to that under edge-level privacy suggests that for large, sparse networks it is feasible to perform differentially private inference on network data under node-level privacy constraints.
 
 \subsubsection*{Setup}

We evaluate the error introduced to structural sufficient statistics for the three synthetic network models with networks of up to $1000$ nodes.  To guarantee $\eps$-differential privacy we project the networks to the space of limited degree graphs and then add Cauchy noise to sufficient statistics, scaled to the restricted sensitivity specified in Table \ref{tab:altsuffstatsrestr} times a $\beta$-smooth upper bound on the projection.\footnote{While we also tested the addition of Laplace noise which gives an $(\eps, \delta)$-differentially private algorithm, we found that for small $\delta$, the scale of Laplace noise was almost a factor of $10$ higher than Cauchy, as the factors of $\delta$ led to very high smooth sensitivity of the projections. Since the Cauchy distribution gives pure $\eps$-DP and gives much better accuracy in the typical case, we present results using Cauchy noise.} Because the Cauchy distribution has fat tails, summary statistics based on the mean and variance are not meaningful measures of noise addition. Therefore, we use the median absolute error normalized by the scale of the statistics to measure the level of distortion introduced to sufficient statistics by the privacy mechanism. We test two possible projections to the space of limited degree networks, one based on a linear program proposed in \cite{BBDS13} and the other based on removing edges incident to nodes of maximum degree proposed in \cite{KNRS13}, both of which are described in detail in \Cref{appendix_projections}. For the linear program we use the GLPK package to find solutions. We hypothesize that the node truncation approach will work better than the LP, because for max degree $k$, the LP requires adding noise scaled to the restricted sensitivity on $\H_{2k}$, while node truncation scales noise to restricted sensitivity on $\H_{k}$. We test $4$ different degree cutoffs: the min, median, max and a conservative estimate of $1.5$ times the max degree over samples on $n$ nodes.

\subsubsection*{Results}

\begin{figure}[hp]
	\caption{Comparison of Relative Median Absolute Error of node-DP sufficient statistics released at a privacy level of $\eps = 0.5$-per statistic for networks from \emph{Model $\mathit{1}$}. Cauchy noise is scaled to the restricted sensitivity times a $\beta$-smooth bound on the local sensitivity of projection. Projection using an LP is shown on the left and using node truncation is shown on the right}
	\label{nodenoise1}
	\centering
	\includegraphics[width=0.5\linewidth]{noise/legendnode.png}\\\vspace{0.2in}
	
	\includegraphics[width=1.0\linewidth]{noise/noisenode1.png}
\end{figure}

We display results for Model $1$ in Figure \ref{nodenoise1} and results for Models $2$ and $3$ in \Cref{appendix_add_results}. Using the node truncation projection, it is possible to perturb the sufficient statistics relatively little.  In general, star and edge statistics can be released with high accuracy, as the restricted sensitivity is scaled to the degree cutoff $k$, while for triangles and two-paths it is scaled to $k^2$. The $k$-two-path statistic has low relative error, as the statistic value tends to be high for networks with many triangles, so noise is unlikely to overwhelm the statistic. However, the magnitude of the $k$-triangle statistic tends to be much lower than the $k$-two-path statistic, hence the difficulty in releasing the $k$-triangle statistic under privacy constraints. 

For all three models, we show that it is possible using the node truncation projection on large networks to add noise well below a relative error of $50\%$ the size of the alternating $k$-triangle statistic.  For instance, looking at the second subplot from the top on the right side of Figure \ref{nodenoise1}, we can see that for for Model $1$, we introduce error of under $25\%$ of the magnitude of the $k$-triangle statistic for networks above $700$ nodes (with either max or median cutoff for $k$.) As we demonstrated for edge-level inference on $300$-node networks drawn from Model $1$, introducing error of $30\%$ of the magnitude of the $k$-triangle statistic enabled highly accurate parameter estimation, so extrapolating to the larger networks, it may be possible to perform accurate inference under node-level privacy.

However, the node-projection is much more sensitive to choice of degree cutoff than projection for the edge-level privacy model. In particular, for edge-level privacy, the projection has fixed global sensitivity of $3$ so changing the degree cutoff has no effect on noise addition, only on the value of sufficient statistics in the projected network. In contrast, for the node-level projections, the $\beta$-smooth bound on local sensitivity of the projection is affected by choice of cutoff. Relative to the LPs projection, the node-truncation projection tends to perform well for conservative choices of the degree cutoff, as choosing the cutoff close to the max degree can lead to high smooth sensitivity (which is particularly true for Models $2$ and $3$ ). For the LP-projection, the opposite is true: aggressive choice of the degree cutoff leads to better performance. This occurs because the LP-projection is closer to optimal smoothness, so the smooth sensitivity of the projection is not much worse for under-estimates of the degree than for over-estimates. However, using the LP requires calibrating noise to the restricted sensitivity on $\H_{2k}$ so this noise addition dominates the noise added, especially for $k$-triangle and two-path where restricted sensitivity is $O(k^2)$ meaning that the restricted sensitivity is worse by a factor of $4$ for the LP as compared to node truncation. We observe that noise addition using the LP tends to be even worse than this factor, however, suggesting that for the sparse networks under consideration, node truncation has low smooth sensitivity.  Additionally, the node truncation projection is much more computationally efficient than the LP in practice, as for large networks of more than 700 nodes it tends to run about $100$ times faster, although some speed-up may be possible using more efficient LP solvers like CPLEX. However, this computational gap is inherent to the two projections as the node truncation projection runs in time $O(n)$ while the LP projection requires solving a linear program with $O(n^2)$ variables. In short, the node truncation projection seems better suited to the setting of differentially private inference over sparse network data than the linear program projection.

In summary, restricted sensitivity using Cauchy noise and the node truncation projection allows for low noise addition for $k$-star, edge, and $k$-two-path sufficient statistics in the strong node-level privacy model. For the $k$-triangle statistic, the error on large networks with conservative estimates of the degree cutoff is comparable to that of edge-level privacy for small networks, suggesting that even for this high sensitivity statistic it is feasible to perform inference for large, sparse networks under the node-level privacy model.

\newpage
 \section{Summary of Findings}\label{sec:summary_findings}

The chapter concludes with a summary of experimental findings:

\begin{itemize}
	\item Calibrating noise to restricted sensitivity leads to substantially lower noise addition than private bounding of local sensitivity for sparse networks with privacy budgets of $\eps = 0.25$ or less per-sufficient statistic (Figure \ref{fig:edge_noise}).
	\item Inference using restricted sensitivity gives more accurate parameter estimates than using private local sensitivity on $300$-node synthetic networks for small privacy budgets of $\eps=1$ or for estimation of $3$ or more parameters (Figures \ref{fig:edgeinfsynth2} and \ref{fig:edgeinfsynth3}). 
	\item Randomized response does not allow for useful inference on synthetic networks of $300$ nodes even for large privacy budgets of $\eps=3$. In particular, it overwhelms interesting features of network structure, causing estimated parameters to resemble those of $G(n,p)$ graphs (Figures\ref{fig:edgeinfsynth1},\ref{fig:edgeinfsynth2},\ref{fig:edgeinfsynth3}). %Experiments from prior work on randomized response in \cite{KKS17} suggest that randomized response only gives useful results for $\eps=3.5$ or larger,  highlighting the shortcoming of this method in enabling useful inference at small privacy budgets.
	\item Restricted sensitivity enables accurate private parameter estimation on real network data, while existing methods do not. In particular, for restricted sensitivity calibrated to $\eps=2$ we can estimate parameters on a $205$-node high school friend network with low error, while maintaining statistical significance of parameters as compared to non-private inference (Table \ref{tab:infalttyp}.) In contrast, private bounding of local sensitivity and randomized response both give highly inaccurate parameter estimates for $\eps=3$ on this dataset (Table \ref{tab:infacc}.) 
	\item In the node-level privacy model, relatively low levels of noise can be added to networks of $700$ or more nodes using a node truncation projection with a conservative estimate of the maximum degree of a network (Figure \ref{nodenoise1} and \Cref{appendix_add_results}.) Extrapolating from the performance of edge-level private inference to the node-level case, suggests that noise addition to sufficient statistics may be low enough for large networks to permit node-level private inference.
\end{itemize}  

