In this chapter, we propose methods for differentially private inference over ERGMs with the alternating and nodal attribute sufficient statistics defined in \Cref{sec:alt_stats}. We propose perturbing the sufficient statistics, taking advantage of restricted sensitivity to limit the amount of noise needed to protect privacy. Then, it is possible to perform Bayesian inference taking into account the level of noise added. Since the restricted sensitivity is public, we are able to do principled inference over the posterior incorporating the randomness of the privacy mechanism, which has been shown to lead to more reliable inference in many cases (see \cite{FGWC16}, \cite{KS16}, \cite{KKS17}, \cite{LM14} for instance). 

Our primary contribution is the proposal to use the machinery of restricted sensitivity in adding noise to sufficient statistics. The advantages of employing restricted sensitivity for inference over ERGMs are threefold:

\begin{itemize}
	\item Calibrating noise to restricted sensitivity enables \emph{lower noise in the edge-adjacency model} than current methods, permitting accurate inference at lower privacy budgets.
	\item Restricted sensitivity permits private release of sufficient statistics under edge level privacy with \emph{private labels}, whereas prior work has treated labels as public.
	\item By using restricted sensitivity, we suggest the first (to our knowledge) method that performs differentially private inference under the \emph{node-adjacency model}, a strictly stronger notion of privacy than the edge-adjacency model.
\end{itemize} 

Restricted sensitivity relies on the hypothesis that the graph we are analyzing is sparse, namely that its max degree node has degree $k$.  There are a number of reasons to believe that the limited degree hypothesis $\H_k$ is a reasonable assumption when modeling real social network data with ERGMs. First, previous empirical analyses of ERGMs have demonstrated that for reasonable parameter values, the distribution tends to put low probability mass on high-degree graphs \cite{Sni+06}. Thus, given that we assume that an observed network is roughly drawn from the probability distribution specified by an ERGM, we believe with high probability that the graph has relatively low degree. Second, many real-world social networks are fairly sparse and have bounded degree. Thus, an analyst is likely to believe that their network data represents a sparse graph and could reasonably choose a degree cutoff based on similar public datasets or domain knowledge.  

\section{Releasing Private Sufficient Statistics}
\label{sec:release_suff_stats}

In this section, we bound the restricted sensitivity under $\H_{k}$ of a number of the most commonly used sufficient statistics in ERGMs. As the following summary shows, in the edge-adjacency case, restricted sensitivity is much lower than global sensitivity for alt-$k$-triangle and alt-$k$-two path, assuming $k << n$. In the node-level case, adding noise scaled to the global sensitivity overwhelms the computed statistics in most cases, motivating the need for restricted sensitivity. For labeled networks, the global sensitivity is very low if labels are considered public and only edges are taken to be private. However, if labels are private, then the restricted sensitivity is much lower than the global sensitivity. 

\begin{table}[!ht]
	\caption{Restricted Sensitivity on $\H_k$ for Common Structural Statistics}
	\begin{center}
	\begin{tabular}{|l|c|c|c|c|}
		\hhline{|=====|}
		 & \multicolumn{2}{c|}{Edge-Level} & \multicolumn{2}{c|}{Node-Level} \\\hline
		& $RS_f(\H_k)$ & $GS_f$ & $RS_f(\H_k)$ & $GS_f$ \\ \hline
		Edges & $1$ & $1$ & $k$  & $n-1$\\ \hline
		Alt $k$-star ($u_\lambda^{(s)}$) & $2\lambda$ & $2\lambda$  & $3 \lambda k$  & $O(n)$\\ \hline
		Alt $k$-triangle  ($u_\gamma^{(t)}$)  & $2(k-1) + \gamma$ & $O(n)$  & $k^2 + (\gamma -1)k$ & $O(n^2)$\\ \hline
		Alt $k$-two-path  ($u_\gamma^{(p)}$)  & $2(k-1)$ & $O(n)$    & $k^2$ & $O(n^2)$\\	
		\hhline{|=====|}
	\end{tabular}
	\end{center}
	\label{tab:altsuffstatsrestr}
\end{table}

\begin{table}[!ht]
		\caption{Restricted Sensitivity on $\H_k$ for Common Statistics of  Labeled Networks}
		\begin{center}
		\begin{tabular}{|l|c|c|c|}
		\hhline{|====|}
		& \multicolumn{1}{c|}{Public Labels} & \multicolumn{2}{c|}{Private Labels} \\\hline
		 & $GS_f$ & $RS_f(\H_k)$ & $GS_f$ \\ \hline
		Homophily &  $1$ & $k$  & $n-1$\\ \hline
		Popularity  & $2$  & $2k$ & $2n$\\ \hline
		Mixing & $1$    & $k$ & $n-1$\\	 \hhline{|====|}
	\end{tabular}
	\label{tab:labeluffstatsrestr}
	\end{center}
\end{table}

Below, we derive the restricted sensitivity of the alternating sufficient statistics of an ERGM under edge level privacy and node level privacy respectively. The ``weighting parameters'' of the alternating statistics $\gamma$ and $\lambda$ are generally set to be small constants between roughly $1$ and $5$ (most empirical work seems to find that values between $1$ and $2$ suffice) so the choice of this parameter has a fairly minor effect on the level of noise.

\subsection{Edge Level Privacy} 

For the alternating $k$-star statistic under edge-level privacy, restricted sensitivity does not
give any advantage over using global sensitivity, as the global sensitivity of this statistic is quite low:

\begin{claim}[Global sensitivity of alternating $k$-star under edge-level privacy]
The global sensitivity of the alternating $k$-star statistic is less than $2\lambda$. 
\end{claim}
\begin{proof}
We use the alternative formulation of the statistic given in \Cref{eq:alternative-k-star}:
$$u_\lambda^{(s)}(x) =  \lambda^2 \sum_{i = 0}^{n-1} \left(\frac{\lambda - 1}{\lambda}\right)^i D_i + 2 \lambda |E| - n \lambda^2$$
Then, consider adjacent graphs $x, x'$ differing in one edge where $x$ has the additional edge. Then, the first term of the alternating $k$-statistic is larger for $x'$ than for $x$ and by at most $2\lambda$ and at least $0$, while the second term is larger for $x$ than for $x'$ by $2\lambda$. Hence, the difference between the alternating $k$-star statistic computed on $x$ and $x'$ is at most $|2\lambda - 0| = 2\lambda$.
\end{proof}

\begin{claim}[Restricted sensitivity of alternating $k$-triangle under edge-level privacy]
The restricted sensitivity of the alternating $k$-triangle statistic under $\H_k$ is less than $2(k-1) + \gamma$.
\end{claim}
\begin{proof}
Consider two adjacent graphs $x, x'\in \H_k$ differing in exactly one edge, so that $x_{ij} = 1$ and $x'_{ij} = 0$. Now, note that for nodes $i$ and $j$, the number of shared partners is the same in $x$ and $x'$ since all edges are the same except for the edge between $i$ and $j$. Then, let $P_{ij} = P'_{ij} = m \leq k-1$ by the limited degree hypothesis. Note that there are $2m$ edges for which $P'_{e} = P_{e} - 1$, since there are two other edges in each triangle. Then, recalling the definition of the alternating $k$-triangle statistic in terms of the shared partners of $i$ and $j$ given in \Cref{eq:alternative-k-tri}:
$$
u_\gamma^{(t)}(x) = \gamma |E| - \gamma \sum_{1 \leq i < j \leq n} x_{ij} \left(\frac{\gamma-1}{\gamma} \right)^{P_{ij}}
$$
we have that 
\begin{align*}
|u_\gamma^{(t)}(x) - u_\gamma^{(t)}(x')| &= \left|\gamma - \gamma \left(\frac{\gamma-1}{\gamma} \right)^{m}  + \gamma\sum_{e= 1}^{2m}  \left[\left(\frac{\gamma-1}{\gamma} \right)^{P_e-1}  - \left(\frac{\gamma-1}{\gamma} \right)^{P_e}\right]    \right|\\
& = \left|\gamma - \gamma \left(\frac{\gamma-1}{\gamma} \right)^{m}  + \sum_{e= 1}^{2m}  \left(\frac{\gamma-1}{\gamma} \right)^{P_e-1}   \right|\\
& \leq 2m + \gamma\\ 
& \leq 2(k-1) + \gamma 
\end{align*}
\end{proof}

Note the usefulness of restricted sensitivity here, in contrast to global sensitivity. The global sensitivity of this statistic is $O(n)$, since in the worst case there could be a graph with an $(n-1)$-triangle where removing the base of the triangle leads to the removal of $O(n)$ triangles. However, if we restrict degrees, we add much less noise.

\begin{claim}[Restricted sensitivity of alternating $k$-two-path under edge-level privacy]
The restricted sensitivity of the alternating $k$-two-path statistic under $\H_k$ is less than $2(k-1)$.
\end{claim}
\begin{proof}
The proof will proceed in roughly the same way as for $k$-triangles. Define $x$ and $x'$ in the same way and recall the definition of the alternating $k$-two-path statistic in terms of shared partners as given in \Cref{eq:alternative-k-two-path}:
$$
u_\gamma^{(p)}(x) = \gamma \binom{n}{2} - \gamma \sum_{1 \leq i < j \leq n} \left(\frac{\gamma-1}{\gamma} \right)^{P_{ij}}
$$
Then, the change between the statistic on $x$ and $x'$ is equal to 
$$|u_\gamma^{(p)}(x) -  u_\gamma^{(p)}(x')| = \sum_{e = 1}^{2m} \left( \frac{\gamma - 1}{\gamma} \right)^{P_e - 1} \leq 2m \leq 2(k-1)$$
\end{proof}

\subsection{Node Level Privacy}

\begin{claim}[Restricted sensitivity of alternating $k$-star under node-level privacy]
The restricted sensitivity with hypothesis $\H_k$ of alternating $k$-star under node-level differential privacy is less than $3\lambda k$.
\end{claim}
\begin{proof}
We will again use the formulation of the alternating $k$-star statistic in terms of degree distribution from \Cref{eq:alternative-k-star}. Now, consider two graphs $x, x' \in \H_k$ differing in one node $i$ of degree $m \leq k$, with all of its incident edges removed in $x'$. Then, the degree of node $i$ is $m$ in $x$ and $0$ in $x'$, while the degrees of $m$ other nodes are $1$ lower in $x'$ than in $x$, so:
\begin{align*}
|u_\lambda^{(s)}(x) - u_\lambda^{(s)}(x')| & = \left|2\lambda m + \lambda^2\left( \left(\frac{\lambda - 1}{\lambda}\right)^m - 1\right) +\sum_{j: x_{ij} = 1} \lambda \left(\frac{\lambda - 1}{\lambda}\right)^{d_j - 1}  \right| \\
& \leq \left|3\lambda m +  \lambda^2\left( \left(\frac{\lambda - 1}{\lambda}\right)^m - 1\right)\right|
\end{align*}
and note that $0 \leq \left(\frac{\lambda - 1}{\lambda}\right)^m \leq 1$ and that $|\lambda^2| \leq 3\lambda m$ for reasonable choices of $k$ and $\lambda$ (since generally we choose $1 < \lambda < 5$, so in order to have the $\lambda^2$ term dominate the $3\lambda k$ term we would have to restrict $k$ to $1$, which would not be interesting or realistic). Thus, because $m \leq k$, the sensitivity is bounded by $3\lambda k$.
\end{proof}

\begin{claim}[Restricted sensitivity of alternating $k$-triangle under node-level privacy]
The restricted sensitivity with hypothesis $\H_k$ of the alternating $k$-triangle statistic under node-level differential privacy is less than $k^2 + (\gamma - 1) k$.
\end{claim}
\begin{proof}
Consider two adjacent graphs $x, x'\in \H_k$ differing in one node $i$ of degree $m$. Now, since each of the $m$ edges incident to node $i$ is removed this changes $m$ edges $x_{ij} = 1$ to $x'_{ij} = 0$, so $E(x) - E(x') = m$ and for each of these $m$ edges 
$$ x_{ij} \left( \frac{\gamma - 1}{\gamma}\right)^{P_{ij}} - x'_{ij} \left( \frac{\gamma - 1}{\gamma}\right)^{P'_{ij}} = \left( \frac{\gamma - 1}{\gamma}\right)^{P_{ij}} $$ so the direct effect of removing the $x_{ij}$ is that $u_\gamma^{(t)}(x') - u_\gamma^{(t)}(x') \leq m \gamma -0$ (ignoring the effect on the shared partners of edges not adjacent to $i$.)

Now, we consider edges $e$ such that the endpoints of $e$ have $i$ as a shared partner. Note that there are $\binom{m}{2} = m^2 - m$ such edges, because we can choose any $2$ edges of $i$ and the endpoints of these edges have $i$ as a shared partner. Now, each of these edges still exists in $x'_{ij}$ but has its number of shared partners decrease by $1$. Then, we have 
\begin{align*}
|u_\gamma^{(t)}(x) - u_\gamma^{(t)}(x')| &= \left|\gamma m - \gamma \sum_{j: x_{ij} = 1}\left(\frac{\gamma-1}{\gamma} \right)^{P_{ij}}  + \sum_{e= 1}^{m^2 - m}  \left(\frac{\gamma-1}{\gamma} \right)^{P_e-1}    \right|\\
& \leq |\gamma m + (m^2 - m)|\\
& \leq k^2 +  (\gamma - 1)k 
\end{align*}
\end{proof}

\begin{claim}[Restricted sensitivity of alternating $k$-two-path under node-level privacy]
The restricted sensitivity with hypothesis $\H_k$ of the alternating $k$-two-path statistic under node-level differential privacy is less than $k^2$. 
\end{claim}
\begin{proof}
As for $k$-triangles, consider two adjacent graphs $x, x' \in \H_k$ differing in node $i$ of degree $m$. Then, the removal of these $m$ edges impacts the shared partners of $m^2$ edges, the $m$ incident to $i$ and the $\binom{m}{2} = m^2 - m$ that have $i$ as a shared partner and the decrease in shared partners for each of these edges can change the statistic by at most $1$ so the overall change is at most $m^2 \leq k^2$.
\end{proof}

\subsection{Private Labels}

If labels are considered public, then the global sensitivity of the sufficient statistics using discrete attributes of nodes given in \Cref{table:node_suff_stats_defn} have low global sensitivity in the edge-adjacency model, since they are effectively counts of edges for nodes with certain attributes, and adjacent graphs have only a single edge changed and all labels kept the same. However, if labels are considered private then the change in a single label could change the count for all edges incident to that node, leading to very high global sensitivity of $O(n)$. By using restricted sensitivity, we can bound the sensitivity to be $O(k)$. Additionally, note that differential homphily and popularity are vectors of queries, with dimension the size of the number of attributes under consideration. However, these queries are structurally disjoint as a change in one attribute can only change the counts of two entries of the vector, making it easy to bound the $\ell_1$-sensitivity of the entire vector. We give the proof for homophily, while the proofs for popularity and mixing follow from the same argument:

\begin{claim}[Restricted sensitivity of homophily with private labels.]
	Both differential and uniform homophily have $\ell_1$-restricted sensitivity $k$.
\end{claim}
\begin{proof}
Recall that for attributes $a_1,...,a_m$ differential homophily is given by  
$$\left(\sum\limits_{i < j} x_{ij} \I (z_i = z_j = a_1),..., \sum\limits_{i < j} x_{ij} \I (z_i = z_j = a_m)\right)$$
 Then, changing nodal attribute $z_i$ from $a$ to $b$ changes the endpoint of at most $k$ edges. If both endpoints of an edge had endpoint $a$, then this reduces the count of entry $a$ in the vector by $1$, while if the endpoints of the edge were $a$ and $b$ to start with, this increases the count in entry $b$ by $1$. These cases are disjoint so the largest $\ell_1$ difference in the vector is $k$.  For uniform homophily, it is easy to see that changing one label could change at most $k$ edges and each edge is counted only once in uniform homophily, so the global sensitivity is $1$.
\end{proof}

\section{Inference Using Noisy Sufficient Statistics}

Now, by projecting a network into $\H_k$ using the projections specified in \Cref{appendix_projections} and then applying the Laplace mechanism (\ref{thm:laplace}), we can release the sufficient statistics of the ERGM in a differentially private manner by calibrating the noise of the Laplace mechanism to the restricted sensitivity. We could now release these sufficient statistics to analysts who wish to study the network, since the likelihood of the ERGM depends on the data only through the sufficient statistics. Using noisy statistics directly for standard inference techniques has been shown to lead to biased estimates, however, as the sufficient statistics may not even be graphical. Therefore, in the framework of Bayesian inference we want to compute the posterior over both the observed network and the privacy mechanism. In particular, letting $\tilde{y}$ be the ``noisy network'' defined by the application of our privacy mechanism to the true network we wish to compute the posterior:
\begin{align}
p(\theta | \tilde{y}) &\propto p(\tilde{y} | \theta) p(\theta) = \sum_{x} p(\tilde{y} | x) p(x|\theta) p(\theta)  
\end{align}
where $p(\tilde{y} | x)$ is the privacy distribution defined by our mechanism, $p(x| \theta)$ is the ERGM distribution and $p(\theta)$ is the prior on $\theta$ which is specified by the analyst.  Then, along the lines of \cite{LM14}, it is simple to modify the Exchange Algorithm for non-private inference to draw from the posterior that incorporates the privacy distribution, as shown in Algorithm $2$.

\begin{algorithm}[!ht]
	\label{alg:privinf}
	\caption{Bayesian Inference for ERGMs with Differentially Private Network Data}
	Input: ERGM distribution $\pi(X | \theta)$, prior $p(\theta)$, noisy network $\tilde{y}$, privacy distribution $\pi_p(\tilde{y} | y)$, number of burn-in draws $r$, symmetric proposal distribution $h(\cdot | \theta)$. \\
	Output: sequence of draws $\theta^{(r)},...\theta^{(T)}$ from posterior distribution $p(\theta | \tilde{y})$.
	
	\vspace{0.1in}
	For {$ t = 1,...,T$}:
	\begin{enumerate}
		\item  Draw parameter vector $\theta^* \sim h(\cdot | \theta^{(t-1)})$
		\item Sample graph $x^* \sim \pi(\cdot | \theta^*)$
		\item Replace $\theta^{(t-1)}$ with $\theta^*$ with probability $\min\left\{1, \alpha_1\right\}$.
		\item Replace $x^{(t-1)}$ with $x^*$ with probability $\min\left\{1, \alpha_2\right\}$.
	\end{enumerate}
	where \begin{align*}
	\alpha_1 &= \frac{p(\theta^*)}{p(\theta^{(t-1)})} \exp\left\{\left(\theta^* - \theta^{(t-1)}\right)^T\left(u(x^{(t-1)}) - u(x^*)\right) \right\} \\
	\alpha_2 & = \frac{\pi_p(\tilde{y} | x^*) }{\pi_p(\tilde{y} | x^{(t-1)})} \exp\left\{\left(\theta^* - \theta^{(t-1)}\right)^T\left(u(x^{(t-1)}) - u(x^*)\right) \right\} 
	\end{align*}
\end{algorithm}

As in the non-private case, Algorithm 2 draws samples from the true posterior of interest as $T \to \infty$ by MCMC theory. Steps $1$ and $2$ can be justified as Gibbs updating steps as in the non-private case, while steps $3$ and $4$ are component-wise Metropolis-Hastings updates, where we update the variables separately rather than in a block, because this tends to lead to higher acceptance ratios and thus faster convergence \cite{GL06}, \cite{LM14}. Intuitively, $x^*$ can be thought of as our best guess of the true underlying network. Then, $\theta^*$ is replaced in step $3$ if it explains this best guess of the network well, while $x^*$ is updated if the new network is likely to be the true network over the noise of the privacy mechanism. Additionally, we propose using the population MCMC version of the exchange algorithm, as this leads to better convergence in practice and still converges to the correct posterior.

Note that $\alpha_1$ does not depend on the choice of privacy mechanism, while $\alpha_2$ is simple to compute under the addition of Laplace noise. In particular, if we add Laplace noise scaled to $L$ (for instance, $L= 3 \cdot RS_f(\H_k)$ in the edge-adjacency case) to the sufficient statistics of the network then:

\begin{align}
\label{eq:privacy_ratio}
\log \frac{\pi_p(\tilde{y} | x^*) }{\pi_p(\tilde{y} | x^{(t-1)})} & = \log \left(Lap\left(\tilde{y} - x^*  | L \right)  \right) -  \log \left(Lap\left(\tilde{y} - x^{(t-1)}  | L \right) \right) \\ \nonumber
& = \frac{|\tilde{y} - x^{(t-1)} | }{L} - \frac{|\tilde{y} - x^* | }{L}
\end{align}

 In the edge-adjacency model, the restricted sensitivity is public, so  we can easily compute the ratio in $\cref{eq:privacy_ratio}$ using $L=3RS_f(\H_k)$ where the factor of $3$ comes from the global sensitivity of the projection. In the node-level case, we compute smooth sensitivity of the projection which cannot be publicly released, but we can release the value of the smooth sensitivity assuming the graph belongs to $\H_k$ as explained in $\Cref{appendix_projections}$, so inference is still valid when the analyst's assumptions about the degree of the graph are met.
 
 In general, we assume that the number of nodes in a graph is known and public. For the case where labels are public, sampling a graph in step $2$ is straightforward as we sample a graph from the space of all possible graphs with the $n$ labeled nodes of the original graph. However, if labels are private, then these labels must be privatized as well. This is straightforward to by releasing a noisy histogram of the labels, which has global sensitivity of $1$ and therefore is high accuracy assuming that there are a limited number of types of labels \cite{DMNS06}. Then, this noisy histogram can be used as the node-set over which graphs are sampled in step $2$ of the algorithm.

\subsubsection{The Full Workflow}

Putting together our bounds on restricted sensitivity and inferential procedure the work-flow for differentially private inference looks roughly as follows, given hypothesis $\H_k$, privacy budget $\eps, \delta$ (where the $\delta$ is necessary only for the node-level case using Laplace noise) and network data $y$:

\begin{enumerate}
	\item Split privacy budget between sufficient statistics under consideration (and potentially using some of the privacy budget for a histogram of private labels).
	\item Project $y$ to $\H_k$ using smooth projections $\mu$ specified for edge and node level privacy respectively in \Cref{appendix_projections}.
	\item Compute and release restricted sensitivity of sufficient statistics.
	\item If labels are considered private, then release noisy histogram of node labels.
	\item Draw noise according to restricted sensitivity (Laplace noise scaled to $3RS_f(\H_k)/\eps$ in the edge-level case and $S_{\mu, -\eps/2\ln\delta} RS_f(\H_k)$ in the node-level case where $\mu$ is the node-truncating projection. Add this noise to sufficient statistics and release these noisy sufficient statistics.
	\item Using the noisy sufficient statistics from step 4 and the restricted sensitivity levels from step 3, perform inference using Algorithm 2. 
\end{enumerate}

Then, privacy follows by applying composition in step $1$, restricted sensitivity with the Laplace Mechanism in steps $2$-$5$ and post-processing in step $6$. Post-processing is particularly useful here, because MCMC methods frequently require tuning of the inference, whereby we run the inferential procedure multiple times and run diagnostics to make sure it converges (for instance, by checking that every $100$ samples from the posterior are not highly correlated.) By post-processing, we can run step $6$ an arbitrary number of times to tune the inferential procedure because differential privacy is provided by steps $1$ to $5$.

\section{Related Work}\label{sec:rel_work}

Our work builds on two proposed methods, both of which only consider the edge-adjacency privacy model with labels taken to be public. The method most closely related to our work is that of Lu and Miklau \cite{LM14} who also suggest adding noise to sufficient statistics and then performing Bayesian inference. In order to avoid adding noise scaled to the high global sensitivity of these statistics, they calibrate noise to a private bound on the local sensitivity of the network. In particular, they use an approach suggested in \cite{KRSY14} to compute a differentially private over-estimate on the local sensitivity and scale noise to this estimated local sensitivity, providing $(\eps, \delta)$-differential privacy and allowing for less noise than calibrating to the global sensitivity when  $GS_{LS_f}$ can be bounded and is small. In particular, in their method, the expected scale of Laplace noise is $\frac{2 LS_f(G)}{\eps} + \frac{4 GS_{LS_f} \ln (1/\delta)}{\eps^2}$ whereas we add noise scaled to $3RS_f(\H_k)/\eps$. For reasonable choice of $k$, the restricted sensitivity is close to the local sensitivity on graph $G$, while the second term can be quite large for small privacy budgets in $\eps$ and $\delta$. Miklau and Lu test their approach with $\delta = 0.1$, which is an unreasonable choice of this parameter in practice, since a method that released the entire dataset one tenth of the time would satisfy $(\eps, \delta)$-DP with this parameter (\Cref{ex:bad_delta2}).  We find through a battery of tests that our proposed method (which takes $\delta = 0$) adds much less noise than the bounding of local sensitivity approach, especially for small privacy budgets. This difference in the magnitude of noise makes a significant difference in the accuracy of inference, as our method can perform accurate inference for realistic small privacy budgets. The primary drawback of our approach is that it requires a reasonable estimate of the the maximum degree of the network, while the private bounding of local sensitivity can calibrate noise to the sparsity of the graph without assumptions on the part of the analyst. However, if the graph is not relatively sparse, bounding local sensitivity may still add significant noise, so this seems like a reasonable assumption for an analyst to be able to make.

 %Miklau and Lu's approach does not extend well to the node-adjacency model, because the local sensitivity of a graph could be much higher than the restricted sensitivity, since any graph is adjacent to a graph with a node of degree $n-1$. Lastly, it is worth noting that the Bayesian inferential method using the exchange algorithm that we employ is based on Lu and Miklau's method, although we extend it to take advantage of population MCMC described in \Cref{appendix_mcmc} which leads to more stable inference in practice.
Another approach suggested by Karwa et. al. \cite{KKS17}, uses randomized response on edges of the network, where the network is thought of as a binary database of $0$s and $1$s indicating the presence or absence of an edge between any two nodes. Then, they use maximum likelihood estimation on this perturbed network taking into account the flipping of edges. The main benefit of this method is that it potentially permits greater flexibility as the perturbed network can be released for public use and researchers can use any sufficient statistics they like. Our method requires a commitment to use a specific set of sufficient statistics, although we bound restricted sensitivity for a fairly broad range of the most commonly used sufficient statistics in ERGMs. The primary drawback of the randomized response approach is that for low privacy budgets, it leads to extensive distortion of the underlying network. For instance, taking $\eps =1$ suggests a probability of flipping each edge of around $25\%$, which for a sparse network in which only $5\%$ of edges are present may completely overwhelm network structure. We test randomized response, using Bayesian inference, as it is straightforward to account for this noise in the Bayesian inferential framework and find, as expected, that their method only works for relatively large privacy budgets, whereas our proposal works for lower, more realistic privacy budgets. 



