We have presented a novel framework for differentially private inference on network data using ERGMs with a variety of sufficient statistics. By taking advantage of the sparsity of many real world networks, our approach allows for inference in the edge-level privacy model with smaller privacy budgets than previous work. Further, our work suggests a path towards feasible differentially private inference under the stronger notion of node-level privacy. 

Our empirical testing demonstrates the utility of our methods for practical inference. In particular, we showed for a variety of synthetic networks that our method outperforms current methods for meaningful privacy budgets of $\eps=1$ and for realistic numbers of sufficient statistics. We demonstrate through a differentially private analysis on a dataset consisting of friendships among high school students that researchers could practically apply our methods for inference on real network data and reach similar conclusions as under non-private inference. Finally, we present evidence that for large networks our approach makes it feasible to protect node-level privacy while estimating parameters accurately. Thus, our proposed approach moves us toward the goal of providing meaningful privacy guarantees to participants in network datasets while also allowing researchers to perform accurate inference on the dataset.  

We conclude with suggestions for future work. Running tests for node differentially-private inference and for inference with private labels on large networks of over $700$ nodes would be useful follow-ups on our experiments. Our proposed framework could also be extended in a number of ways:

\begin{itemize}
	\item \textbf{Drawing synthetic networks from privately fitted ERGMs.} Currently, there exist ad-hoc methods for releasing ``anonymized'' data to researchers for statistical analysis. A common approach taken by statistical agencies is to fit an ERGM to a sensitive network dataset and then release a network drawn from the fitted model for use by researchers \cite{ergm}. Since our proposed methods allow for accurate parameter estimation, it may be possible to simulate networks from ERGMs using differentially private parameter estimates to generate rigorously privatized networks. Doing so requires understanding how variation in parameter estimates impacts the probability distribution defined by these parameters. A measurement of distance between distributions like KL-divergence could be helpful in understanding this difference. However, it is only known how to approximate KL-divergence between ERGMs for maximum-likelihood estimates of parameters \cite{HG10}, not Bayesian posterior means. Establishing a useful framework for understanding the difference in ERGM probability distributions defined by parameters inferred using Bayesian inference may be a natural starting point.
	\item \textbf{Adapting more scalable inference methods for differentially private inference.} Recently, more efficient inference methods for ERGMs have been proposed, which can perform inference on networks of well over $1000$ nodes in reasonable time \cite{BFM17}. A simple approach (since noise addition is very low for large networks) would be to use these inference methods directly on noisy sufficient statistics without accounting for noise introduced by the privacy mechanism at all. This could be an interesting starting point for testing the usefulness of restricted sensitivity on larger networks. Ideally, more scalable methods could be adapted to incorporate the privacy mechanism and thus infer parameters of the private posterior distribution as our method does.
	\item \textbf{Privacy over directed networks.} The sufficient statistics described in our work can be defined analogously for networks with directed edges, which describe many real world datasets \cite{LKR12}. Proving differential privacy requires bounding the restricted sensitivity of these new sufficient statistics. It may be possible to do so using a similar approach to ours, namely by defining triangle and two-path statistics in terms of an analog to shared partners on directed networks. 
	\item \textbf{Comparison of Maximum Likelihood Estimation and Bayesian Inference} In this thesis we considered Bayesian inference for ERGMs both because it constitutes the state-of-the art in inference on ERGMs and because this allowed for simple and intuitive incorporation of the noise of the privacy mechanism into the inferential procedure. However, it is straightforward to incorporate the noise of our restricted sensitivity mechanism into the maximum likelihood estimation method originally proposed by Karwa et al. \cite{KKS17} for inference using networks perturbed by randomized response. Since maximum likelihood estimation constitutes the other most common inference procedure in practice, it may be useful to develop both maximum likelihood and Bayesian approaches for differentially private inference. Further, comparing the choice of inference procedure on noisy data while fixing the noise addition procedure could provide insight into the trade-offs between these two inferential frameworks under differential privacy constraints.
\end{itemize}